import type { Service } from '../types/api'

/**
 * Comprehensive model database based on OpenRouter and major providers
 * This includes cloud-hosted and self-hosted models with complete metadata
 */

export const COMPREHENSIVE_MODELS: Service[] = [
  // ===== OpenAI Models =====
  {
    id: 1001,
    providerId: 1,
    name: 'GPT-4 Turbo',
    description: 'Most capable GPT-4 model with 128K context, optimized for chat and code generation',
    modelFamily: 'gpt',
    baseModel: 'gpt-4-turbo-preview',
    pricePer1KTokens: 0.01,
    inputPricePer1MTokens: 10.0,
    outputPricePer1MTokens: 30.0,
    trialTokens: 50000,
    providerName: 'OpenAI',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 128000,
    maxOutputTokens: 4096,
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    useCases: ['programming', 'analysis', 'creative-writing', 'research'],
    features: { functionCalling: true, vision: true, streaming: true, jsonMode: true },
    apiCompatibility: ['openai'],
    status: 'active',
    rating: 4.8,
    reviewCount: 2547,
  },
  {
    id: 1002,
    providerId: 1,
    name: 'GPT-3.5 Turbo',
    description: 'Fast and cost-effective model for simple tasks',
    modelFamily: 'gpt',
    baseModel: 'gpt-3.5-turbo',
    pricePer1KTokens: 0.0005,
    inputPricePer1MTokens: 0.5,
    outputPricePer1MTokens: 1.5,
    trialTokens: 500000,
    providerName: 'OpenAI',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 16000,
    maxOutputTokens: 4096,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['programming', 'translation', 'marketing'],
    features: { functionCalling: true, streaming: true, jsonMode: true },
    apiCompatibility: ['openai'],
    status: 'active',
    rating: 4.6,
    reviewCount: 5234,
  },
  {
    id: 1003,
    providerId: 1,
    name: 'o1-preview',
    description: 'Advanced reasoning model for complex problem solving',
    modelFamily: 'o1',
    baseModel: 'o1-preview',
    pricePer1KTokens: 0.015,
    inputPricePer1MTokens: 15.0,
    outputPricePer1MTokens: 60.0,
    providerName: 'OpenAI',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 128000,
    maxOutputTokens: 32768,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['research', 'analysis', 'programming'],
    features: { streaming: true },
    apiCompatibility: ['openai'],
    status: 'active',
    rating: 4.9,
    reviewCount: 892,
  },

  // ===== Anthropic Models =====
  {
    id: 2001,
    providerId: 2,
    name: 'Claude 3.5 Sonnet',
    description: 'Most intelligent Claude model with 200K context, excellent for complex tasks',
    modelFamily: 'claude',
    baseModel: 'claude-3-5-sonnet-20241022',
    pricePer1KTokens: 0.003,
    inputPricePer1MTokens: 3.0,
    outputPricePer1MTokens: 15.0,
    trialTokens: 100000,
    providerName: 'Anthropic',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 200000,
    maxOutputTokens: 8192,
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    useCases: ['programming', 'analysis', 'creative-writing', 'research'],
    features: { functionCalling: true, vision: true, streaming: true },
    apiCompatibility: ['anthropic', 'openai'],
    status: 'active',
    rating: 4.9,
    reviewCount: 1876,
  },
  {
    id: 2002,
    providerId: 2,
    name: 'Claude 3.5 Haiku',
    description: 'Fastest and most compact Claude model for quick tasks',
    modelFamily: 'claude',
    baseModel: 'claude-3-5-haiku-20241022',
    pricePer1KTokens: 0.0008,
    inputPricePer1MTokens: 0.8,
    outputPricePer1MTokens: 4.0,
    trialTokens: 200000,
    providerName: 'Anthropic',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 200000,
    maxOutputTokens: 8192,
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    useCases: ['programming', 'translation', 'marketing', 'data-extraction'],
    features: { functionCalling: true, vision: true, streaming: true },
    apiCompatibility: ['anthropic', 'openai'],
    status: 'active',
    rating: 4.7,
    reviewCount: 1234,
  },

  // ===== Google Models =====
  {
    id: 3001,
    providerId: 3,
    name: 'Gemini 1.5 Pro',
    description: 'Google\'s most capable model with 1M context window',
    modelFamily: 'gemini',
    baseModel: 'gemini-1.5-pro',
    pricePer1KTokens: 0.00125,
    inputPricePer1MTokens: 1.25,
    outputPricePer1MTokens: 5.0,
    trialTokens: 75000,
    providerName: 'Google',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 1000000,
    maxOutputTokens: 8192,
    inputModalities: ['text', 'image', 'video', 'audio'],
    outputModalities: ['text'],
    useCases: ['programming', 'analysis', 'research', 'data-extraction'],
    features: { functionCalling: true, vision: true, streaming: true },
    apiCompatibility: ['openai', 'google'],
    status: 'active',
    rating: 4.7,
    reviewCount: 1543,
  },
  {
    id: 3002,
    providerId: 3,
    name: 'Gemini 1.5 Flash',
    description: 'Fast and efficient model for high-volume tasks',
    modelFamily: 'gemini',
    baseModel: 'gemini-1.5-flash',
    pricePer1KTokens: 0.000075,
    inputPricePer1MTokens: 0.075,
    outputPricePer1MTokens: 0.3,
    trialTokens: 500000,
    providerName: 'Google',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 1000000,
    maxOutputTokens: 8192,
    inputModalities: ['text', 'image', 'video', 'audio'],
    outputModalities: ['text'],
    useCases: ['programming', 'translation', 'marketing', 'data-extraction'],
    features: { functionCalling: true, vision: true, streaming: true },
    apiCompatibility: ['openai', 'google'],
    status: 'active',
    rating: 4.5,
    reviewCount: 987,
  },

  // ===== Meta Llama (Open Source / Self-Hosted) =====
  {
    id: 4001,
    providerId: 4,
    name: 'Llama 3.3 70B Instruct',
    description: 'Latest open-source Llama model with improved reasoning capabilities',
    modelFamily: 'llama',
    baseModel: 'llama-3.3-70b-instruct',
    pricePer1KTokens: 0.0006,
    inputPricePer1MTokens: 0.59,
    outputPricePer1MTokens: 0.79,
    trialTokens: 300000,
    providerName: 'Meta',
    providerVerified: true,
    deploymentType: 'both',
    selfHostedConfig: {
      requiresOwnInfrastructure: true,
      minimumSpecs: '4x A100 GPUs or 8x H100 GPUs',
      dockerImage: 'meta-llama/llama-3.3-70b',
      setupComplexity: 'medium',
    },
    contextWindow: 128000,
    maxOutputTokens: 4096,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['programming', 'analysis', 'creative-writing', 'research'],
    features: { functionCalling: true, streaming: true, jsonMode: true },
    apiCompatibility: ['openai'],
    status: 'active',
    rating: 4.6,
    reviewCount: 743,
  },
  {
    id: 4002,
    providerId: 4,
    name: 'Llama 3.1 8B Instruct',
    description: 'Small, efficient open-source model for self-hosting',
    modelFamily: 'llama',
    baseModel: 'llama-3.1-8b-instruct',
    pricePer1KTokens: 0.00005,
    inputPricePer1MTokens: 0.05,
    outputPricePer1MTokens: 0.08,
    trialTokens: 1000000,
    providerName: 'Meta',
    providerVerified: true,
    deploymentType: 'both',
    selfHostedConfig: {
      requiresOwnInfrastructure: true,
      minimumSpecs: '1x RTX 4090 or similar (24GB VRAM)',
      dockerImage: 'meta-llama/llama-3.1-8b',
      setupComplexity: 'easy',
    },
    contextWindow: 128000,
    maxOutputTokens: 2048,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['programming', 'translation', 'marketing'],
    features: { streaming: true, jsonMode: true },
    apiCompatibility: ['openai'],
    status: 'active',
    rating: 4.4,
    reviewCount: 567,
  },

  // ===== DeepSeek (Chinese Provider) =====
  {
    id: 5001,
    providerId: 5,
    name: 'DeepSeek-V3',
    description: 'Advanced Chinese reasoning model with excellent performance',
    modelFamily: 'deepseek',
    baseModel: 'deepseek-v3',
    pricePer1KTokens: 0.00027,
    inputPricePer1MTokens: 0.27,
    outputPricePer1MTokens: 1.1,
    trialTokens: 250000,
    providerName: 'DeepSeek',
    providerVerified: true,
    deploymentType: 'both',
    contextWindow: 64000,
    maxOutputTokens: 8192,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['programming', 'analysis', 'research', 'translation'],
    features: { functionCalling: true, streaming: true, jsonMode: true },
    apiCompatibility: ['openai'],
    geographic: { country: 'China', region: 'CN-East', city: 'Beijing' },
    status: 'active',
    rating: 4.7,
    reviewCount: 1234,
  },
  {
    id: 5002,
    providerId: 5,
    name: 'DeepSeek-R1',
    description: 'Reasoning-focused model optimized for complex problem solving',
    modelFamily: 'deepseek',
    baseModel: 'deepseek-r1',
    pricePer1KTokens: 0.00055,
    inputPricePer1MTokens: 0.55,
    outputPricePer1MTokens: 2.19,
    trialTokens: 150000,
    providerName: 'DeepSeek',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 64000,
    maxOutputTokens: 8192,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['research', 'analysis', 'programming'],
    features: { functionCalling: true, streaming: true },
    apiCompatibility: ['openai'],
    geographic: { country: 'China', region: 'CN-East', city: 'Beijing' },
    status: 'active',
    rating: 4.8,
    reviewCount: 456,
  },

  // ===== Qwen (Alibaba) =====
  {
    id: 6001,
    providerId: 6,
    name: 'Qwen 2.5 72B Instruct',
    description: 'Alibaba\'s powerful multilingual model with strong Chinese language support',
    modelFamily: 'qwen',
    baseModel: 'qwen-2.5-72b-instruct',
    pricePer1KTokens: 0.00035,
    inputPricePer1MTokens: 0.35,
    outputPricePer1MTokens: 1.4,
    trialTokens: 200000,
    providerName: 'Alibaba Qwen',
    providerVerified: true,
    deploymentType: 'both',
    selfHostedConfig: {
      requiresOwnInfrastructure: true,
      minimumSpecs: '4x A100 GPUs',
      setupComplexity: 'medium',
    },
    contextWindow: 32000,
    maxOutputTokens: 8192,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['programming', 'translation', 'analysis', 'creative-writing'],
    features: { functionCalling: true, streaming: true, jsonMode: true },
    apiCompatibility: ['openai'],
    geographic: { country: 'China', region: 'CN-East', city: 'Hangzhou' },
    status: 'active',
    rating: 4.6,
    reviewCount: 892,
  },
  {
    id: 6002,
    providerId: 6,
    name: 'Qwen 2.5 Coder 32B',
    description: 'Specialized coding model with excellent performance on programming tasks',
    modelFamily: 'qwen',
    baseModel: 'qwen-2.5-coder-32b-instruct',
    pricePer1KTokens: 0.0003,
    inputPricePer1MTokens: 0.3,
    outputPricePer1MTokens: 1.2,
    trialTokens: 250000,
    providerName: 'Alibaba Qwen',
    providerVerified: true,
    deploymentType: 'both',
    contextWindow: 32000,
    maxOutputTokens: 8192,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['programming', 'analysis'],
    features: { functionCalling: true, streaming: true, jsonMode: true },
    apiCompatibility: ['openai'],
    geographic: { country: 'China', region: 'CN-East', city: 'Hangzhou' },
    status: 'active',
    rating: 4.7,
    reviewCount: 543,
  },

  // ===== Mistral AI =====
  {
    id: 7001,
    providerId: 7,
    name: 'Mistral Large 2',
    description: 'Mistral\'s flagship model with 128K context for complex tasks',
    modelFamily: 'mistral',
    baseModel: 'mistral-large-2407',
    pricePer1KTokens: 0.003,
    inputPricePer1MTokens: 3.0,
    outputPricePer1MTokens: 9.0,
    trialTokens: 50000,
    providerName: 'Mistral AI',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 128000,
    maxOutputTokens: 8192,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['programming', 'analysis', 'creative-writing', 'research'],
    features: { functionCalling: true, streaming: true, jsonMode: true },
    apiCompatibility: ['openai', 'mistral'],
    geographic: { country: 'France', region: 'EU-West', city: 'Paris' },
    compliance: ['GDPR', 'SOC2'],
    status: 'active',
    rating: 4.7,
    reviewCount: 678,
  },
  {
    id: 7002,
    providerId: 7,
    name: 'Mixtral 8x22B',
    description: 'Powerful mixture-of-experts model, open-source and self-hostable',
    modelFamily: 'mistral',
    baseModel: 'mixtral-8x22b-instruct',
    pricePer1KTokens: 0.0009,
    inputPricePer1MTokens: 0.9,
    outputPricePer1MTokens: 0.9,
    trialTokens: 150000,
    providerName: 'Mistral AI',
    providerVerified: true,
    deploymentType: 'both',
    selfHostedConfig: {
      requiresOwnInfrastructure: true,
      minimumSpecs: '8x A100 GPUs (80GB)',
      setupComplexity: 'advanced',
    },
    contextWindow: 64000,
    maxOutputTokens: 4096,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['programming', 'analysis', 'creative-writing'],
    features: { functionCalling: true, streaming: true, jsonMode: true },
    apiCompatibility: ['openai', 'mistral'],
    geographic: { country: 'France', region: 'EU-West', city: 'Paris' },
    compliance: ['GDPR'],
    status: 'active',
    rating: 4.6,
    reviewCount: 432,
  },

  // ===== xAI Grok =====
  {
    id: 8001,
    providerId: 8,
    name: 'Grok Beta',
    description: 'xAI\'s conversational model with real-time knowledge',
    modelFamily: 'grok',
    baseModel: 'grok-beta',
    pricePer1KTokens: 0.005,
    inputPricePer1MTokens: 5.0,
    outputPricePer1MTokens: 15.0,
    trialTokens: 25000,
    providerName: 'xAI',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 131072,
    maxOutputTokens: 4096,
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    useCases: ['analysis', 'research', 'creative-writing'],
    features: { vision: true, streaming: true },
    apiCompatibility: ['openai'],
    status: 'active',
    rating: 4.5,
    reviewCount: 234,
  },

  // ===== Specialized Models =====
  {
    id: 9001,
    providerId: 9,
    name: 'Amazon Nova Pro',
    description: 'AWS Bedrock model with enterprise features',
    modelFamily: 'nova',
    baseModel: 'amazon-nova-pro',
    pricePer1KTokens: 0.0008,
    inputPricePer1MTokens: 0.8,
    outputPricePer1MTokens: 3.2,
    providerName: 'Amazon AWS',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 300000,
    maxOutputTokens: 5000,
    inputModalities: ['text', 'image', 'video'],
    outputModalities: ['text'],
    useCases: ['analysis', 'data-extraction', 'research'],
    features: { streaming: true },
    apiCompatibility: ['openai'],
    geographic: { country: 'USA', region: 'US-East' },
    compliance: ['SOC2', 'HIPAA', 'ISO27001'],
    status: 'active',
    rating: 4.4,
    reviewCount: 345,
  },
  {
    id: 9002,
    providerId: 10,
    name: 'Perplexity Sonar Pro',
    description: 'Search-augmented model with real-time web access',
    modelFamily: 'perplexity',
    baseModel: 'sonar-pro',
    pricePer1KTokens: 0.003,
    inputPricePer1MTokens: 3.0,
    outputPricePer1MTokens: 15.0,
    providerName: 'Perplexity',
    providerVerified: true,
    deploymentType: 'cloud',
    contextWindow: 127072,
    maxOutputTokens: 4096,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['research', 'analysis', 'data-extraction'],
    features: { streaming: true },
    apiCompatibility: ['openai'],
    status: 'active',
    rating: 4.6,
    reviewCount: 456,
  },

  // ===== Self-Hosted / Open Source Models =====
  {
    id: 10001,
    providerId: 11,
    name: 'OLMo 3 32B Think',
    description: 'Open-source reasoning model from Allen Institute for AI',
    modelFamily: 'olmo',
    baseModel: 'olmo-3-32b-think',
    pricePer1KTokens: 0,
    inputPricePer1MTokens: 0,
    outputPricePer1MTokens: 0,
    providerName: 'Allen Institute for AI',
    providerVerified: true,
    deploymentType: 'self-hosted',
    selfHostedConfig: {
      requiresOwnInfrastructure: true,
      minimumSpecs: '2x A100 GPUs or 4x RTX 4090',
      dockerImage: 'allenai/olmo-3-32b-think',
      setupComplexity: 'medium',
    },
    contextWindow: 16384,
    maxOutputTokens: 4096,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['research', 'analysis', 'programming'],
    features: { streaming: true },
    apiCompatibility: ['openai'],
    status: 'active',
    rating: 4.3,
    reviewCount: 123,
  },
  {
    id: 10002,
    providerId: 12,
    name: 'NVIDIA Nemotron 70B',
    description: 'High-performance model optimized for NVIDIA hardware',
    modelFamily: 'nemotron',
    baseModel: 'nvidia-nemotron-70b',
    pricePer1KTokens: 0.0006,
    inputPricePer1MTokens: 0.6,
    outputPricePer1MTokens: 0.6,
    providerName: 'NVIDIA',
    providerVerified: true,
    deploymentType: 'both',
    selfHostedConfig: {
      requiresOwnInfrastructure: true,
      minimumSpecs: '4x H100 GPUs or 8x A100 GPUs',
      setupComplexity: 'advanced',
    },
    contextWindow: 32768,
    maxOutputTokens: 4096,
    inputModalities: ['text'],
    outputModalities: ['text'],
    useCases: ['programming', 'analysis', 'research'],
    features: { functionCalling: true, streaming: true, jsonMode: true },
    apiCompatibility: ['openai'],
    status: 'active',
    rating: 4.5,
    reviewCount: 234,
  },
]

/**
 * Get models by deployment type
 */
export function getModelsByDeploymentType(type: 'cloud' | 'self-hosted' | 'both'): Service[] {
  return COMPREHENSIVE_MODELS.filter(m => m.deploymentType === type || m.deploymentType === 'both')
}

/**
 * Get models by provider name
 */
export function getModelsByProvider(providerName: string): Service[] {
  return COMPREHENSIVE_MODELS.filter(m =>
    m.providerName?.toLowerCase() === providerName.toLowerCase()
  )
}

/**
 * Get models by use case
 */
export function getModelsByUseCase(useCase: string): Service[] {
  return COMPREHENSIVE_MODELS.filter(m =>
    m.useCases?.includes(useCase as any)
  )
}

/**
 * Get models by input modality
 */
export function getModelsByInputModality(modality: string): Service[] {
  return COMPREHENSIVE_MODELS.filter(m =>
    m.inputModalities?.includes(modality as any)
  )
}

/**
 * Get free/self-hosted models
 */
export function getFreeModels(): Service[] {
  return COMPREHENSIVE_MODELS.filter(m =>
    m.pricePer1KTokens === 0 || m.deploymentType === 'self-hosted'
  )
}
